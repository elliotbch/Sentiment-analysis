# ğŸ¦ Analyse de Sentiment des Tweets avec BERT

Ce projet utilise des techniques avancÃ©es de traitement du langage naturel pour classifier les sentiments exprimÃ©s dans les tweets. En utilisant le modÃ¨le BERT et d'autres approches, nous avons atteint une prÃ©cision de **78%** pour la classification en trois catÃ©gories : positif, neutre et nÃ©gatif.

## ğŸ“‹ Table des matiÃ¨res

1. [Introduction](#introduction)
2. [Dataset](#dataset)
3. [PrÃ©traitement](#prÃ©traitement)
4. [ModÃ¨les](#modÃ¨les)
5. [RÃ©sultats](#rÃ©sultats)
6. [Discussion](#discussion)
7. [Conclusion](#conclusion)
8. [Contributeurs](#contributeurs)

## ğŸ“– Introduction

Dans l'Ã¨re numÃ©rique actuelle, l'analyse des sentiments sur les rÃ©seaux sociaux est devenue cruciale pour comprendre l'opinion publique. Ce projet vise Ã  dÃ©velopper un modÃ¨le capable de classifier avec prÃ©cision les sentiments exprimÃ©s dans les tweets, contribuant ainsi Ã  une meilleure comprÃ©hension des discussions en ligne.

## ğŸ“Š Dataset

Le dataset provient de la bibliothÃ¨que "Data for Everyone" de Figure Eight, spÃ©cialement conÃ§u pour l'analyse de sentiments des tweets.

- **Composition** :
  - Ensemble d'entraÃ®nement : 25,732 tweets labellisÃ©s
  - Ensemble de test : Tweets non labellisÃ©s
- **CaractÃ©ristiques** :
  - 3 classes de sentiment : positif, neutre, nÃ©gatif
  - DÃ©sÃ©quilibre des classes : 10,018 neutres, 8,711 positifs, 7,003 nÃ©gatifs

![Distribution des sentiments](https://cdn.mathpix.com/cropped/2025_03_18_6fd9357c09fc794ee3a7g-1.jpg?height=570&width=835&top_left_ ğŸ§¹ PrÃ©traitement

Nous avons appliquÃ© plusieurs techniques de prÃ©traitement pour amÃ©liorer la qualitÃ© des donnÃ©es :

1. ğŸš« Suppression des mots vides
2. ğŸ”„ Lemmatisation avec Spacy
3. ğŸ”— Suppression des URLs
4. ğŸ˜€ Conversion des emojis et Ã©moticÃ´nes en mots
5. âœï¸ Correction orthographique
6. ğŸ”¤ Normalisation des mots avec rÃ©pÃ©titions de lettres
7. ğŸ’¬ Conversion des abrÃ©viations de chat
8. ğŸ—‘ï¸ Suppression des handles Twitter et des donnÃ©es numÃ©riques

## ğŸ§  ModÃ¨les

### TextBlob et VADER

Nous avons d'abord testÃ© deux approches basÃ©es sur le lexique :

- **TextBlob** : Utilise un dictionnaire de mots avec des scores de sentiment prÃ©dÃ©finis.
- **VADER** : SpÃ©cialement conÃ§u pour l'analyse de sentiment des mÃ©dias sociaux.

### BERT

Notre modÃ¨le principal utilise BERT (Bidirectional Encoder Representations from Transformers) :

- Architecture : Transformers avec attention bidirectionnelle
- PrÃ©traitement : Tokenisation spÃ©cifique Ã  BERT
- Fine-tuning : AdaptÃ© Ã  notre tÃ¢che de classification de sentiments

## ğŸ† RÃ©sultats

| ModÃ¨le   | Macro F1-Score |
|----------|----------------|
| TextBlob | 0.60           |
| VADER    | 0.64           |
| BERT     | 0.78           |

BERT surpasse significativement les autres modÃ¨les, dÃ©montrant sa capacitÃ© Ã  capturer les nuances complexes du langage.

![Matrice de confusion BERT](https://cdn.mathpix.com/cropped/2025_03_18_6fd9357c09fc794ee3a7g-5.jpg?height=586&width=795&top_left_ ğŸ’¡ Discussion

- BERT excelle dans la comprÃ©hension du contexte et des subtilitÃ©s linguistiques.
- Les modÃ¨les basÃ©s sur le lexique (TextBlob, VADER) sont plus rapides mais moins prÃ©cis.
- DÃ©fis : sarcasme, dialectes, contexte manquant.

## ğŸ“ Conclusion

Notre Ã©tude dÃ©montre l'efficacitÃ©  de BERT pour l'analyse de sentiment des tweets, tout en soulignant l'importance de choisir le modÃ¨le appropriÃ© selon les contraintes spÃ©cifiques de l'application.

## ğŸ¤ Contributeurs

Ce projet a Ã©tÃ© rÃ©alisÃ© par :
- Victor Mayaud
- Elliot Bouchy
- Aymeric Legros
- Naveen Johnson Vallavanatt

Sous la supervision du Professeur Pietro Michiardi, EURECOM, France.
